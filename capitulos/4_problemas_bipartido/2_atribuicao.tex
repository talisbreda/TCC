% ----------------------------------------------------------------------------------------------
% 3.2.1. Problema de atribuição (Assignment Problem)
% ----------------------------------------------------------------------------------------------
\newpage
\subsection{Problema de atribuição (Assignment Problem)}
\label{sec:assignment_problem}

\subsubsection{Descrição do problema}

O problema de atribuição, também conhecido como problema do emparelhamento ponderado, consiste em encontrar uma combinação ótima de atribuições entre dois conjuntos disjuntos, minimizando o custo total associado a essas atribuições. Exemplo: Considere $N$ trabalhadores e $N$ tarefas, onde cada trabalhador pode ser designado a exatamente uma tarefa, e cada tarefa deve ser atribuída a exatamente um trabalhador. O custo de atribuir o trabalhador i à tarefa j é representado por uma matriz de custos $W = [w_{ij}]$ \cite{lawler}. O objetivo é encontrar um conjunto de atribuições que minimize o custo total.

\subsubsection{Propriedades}

\subsubsection{Algoritmos exatos}

% \paragraph{Método Húngaro}
\paragraph{Método Húngaro}

O método Húngaro é um algoritmo eficiente para resolver o problema de atribuição em tempo polinomial. Ele foi desenvolvido por Harold Kuhn em 1955 e é baseado no trabalho de Dénes Kőnig e Jenő Egerváry sobre emparelhamentos em grafos bipartidos \cite{jungnickel}.

O método se baseia em manter um conjunto de potenciais para os vértices dos dois conjuntos do grafo bipartido, sendo $u_i$ o potencial do vértice i no conjunto esquerdo e $v_j$ o potencial do vértice j no conjunto direito. A regra que o algoritmo mantém é que para cada aresta $(i,j)$, a soma dos potenciais deve ser maior ou igual ao custo da aresta, ou seja, $u_i + v_j \geq w_{ij}$. 

Cria-se um subgrafo de igualdade $H_{u,v}$ contendo apenas as arestas onde a soma dos potenciais é igual ao custo da aresta, ou seja, $u_i + v_j = w_{ij}$. O algoritmo então tenta encontrar um emparelhamento máximo neste subgrafo de igualdade. Se o emparelhamento encontrado cobre todos os vértices do conjunto esquerdo, então ele é ótimo para o problema de atribuição original. Caso contrário, o algoritmo ajusta os potenciais para criar novas arestas de igualdade e repete o processo até encontrar um emparelhamento máximo que cubra todos os vértices do conjunto esquerdo \cite{jungnickel}.

Em seguida o pseudo-código do método Húngaro:

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{HUNGARIAN($n, w; mate$)}{
        
        % Lines 1-3
        \lFor{$v \in V$}{ $mate(v) \leftarrow 0$ }
        \lFor{$i = 1$ \KwTo $n$}{ $u_i \leftarrow \max \{ w_{ij} : j=1,\dots,n \}; v_i \leftarrow 0$ }
        $nrex \leftarrow n$\;

        % Line 4: While Loop
        \While{$nrex \neq 0$}{
            
            % Line 5
            \lFor{$i = 1$ \KwTo $n$}{ $m(i) \leftarrow \text{false}; p(i) \leftarrow 0; \delta_i \leftarrow \infty$ }
            $aug \leftarrow \text{false}; Q \leftarrow \{ i \in S : mate(i) = 0 \}$\;
            
            % Line 7: Repeat Loop
            \Repeat{$aug = \text{true}$}{
                remove an arbitrary vertex $i$ from $Q$; $m(i) \leftarrow \text{true}; j \leftarrow 1$\;
                
                % Line 9: Inner While
                \While{$aug = \text{false}$ \KwAnd $j \leq n$}{
                    \If{$mate(i) \neq j'$}{
                         \If{$u_i + v_j - w_{ij} < \delta_j$}{
                            $\delta_j \leftarrow u_i + v_j - w_{ij}; p(j) \leftarrow i$\;
                            \If{$\delta_j = 0$}{
                                \eIf{$mate(j') = 0$}{
                                    AUGMENT($mate, p, j'; mate$)\;
                                    $aug \leftarrow \text{true}; nrex \leftarrow nrex - 1$\;
                                }{
                                    $Q \leftarrow Q \cup \{ mate(j') \}$\;
                                }
                            }
                        }
                    }
                    $j \leftarrow j + 1$\;
                }
                
                % Line 24: Check if augmentation failed and Q is empty
                \If{$aug = \text{false}$ \KwAnd $Q = \emptyset$}{
                    $J \leftarrow \{ i \in S : m(i) = \text{true} \}; K \leftarrow \{ j' \in T : \delta_j = 0 \}$\;
                    $\delta \leftarrow \min \{ \delta_j : j' \in T \setminus K \}$\;
                    \lFor{$i \in J$}{ $u_i \leftarrow u_i - \delta$ }
                    \lFor{$j' \in K$}{ $v_j \leftarrow v_j + \delta$ }
                    \lFor{$j' \in T \setminus K$}{ $\delta_j \leftarrow \delta_j - \delta$ }
                    $X \leftarrow \{ j' \in T \setminus K : \delta_j = 0 \}$\;
                    
                    \eIf{$mate(j') \neq 0$ for all $j' \in X$}{
                        \lFor{$j' \in X$}{ $Q \leftarrow Q \cup \{ mate(j') \}$ }
                    }{
                        choose $j' \in X$ with $mate(j') = 0$\;
                        AUGMENT($mate, p, j'; mate$)\;
                        $aug \leftarrow \text{true}; nrex \leftarrow nrex - 1$\;
                    }
                }
            }
        }
    }
    \caption{Algoritmo Húngaro \cite{jungnickel}}
    \label{alg:hungarian}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{AUGMENT($mate, p, j'; mate$)}{
        \Repeat{$next = 0$}{
            $i \leftarrow p(j); mate(j') \leftarrow i; next \leftarrow mate(i); mate(i) \leftarrow j'$\;
            \If{$next \neq 0$}{
                $j' \leftarrow next$\;
            }
        }
    }
    \caption{Método AUGMENT \cite{jungnickel}}
    \label{alg:augment}
\end{algorithm}

\paragraph{Jonker-Volgenant} 

O algoritmo de Jonker-Volgenant é uma evolução otimizada para a resolução do problema de atribuição linear, proposto por Roy Jonker e Anton Volgenant em 1987. Ele foi desenvolvido para superar o desempenho prático do método Húngaro, especialmente em grafos densos, combinando a teoria de dualidade com estratégias de inicialização e busca mais eficientes \cite{jonker}.

Assim como o método Húngaro, este algoritmo baseia-se na manutenção de potenciais duais ($u_i$ e $v_j$) e respeita as condições de folga complementar. No entanto, sua principal distinção conceitual é o uso da estratégia de Caminho Aumentante Mais Curto (Shortest Augmenting Path). Ao invés de construir emparelhamentos máximos em fases distintas, o algoritmo foca em encontrar o caminho de custo mínimo que conecta uma linha não atribuída a uma coluna livre.

O processo inicia com heurísticas avançadas (conhecidas como redução de colunas e transferência de redução) para resolver rapidamente as atribuições triviais. Para os vértices restantes, o algoritmo realiza uma busca similar ao algoritmo de Dijkstra: ele explora o grafo para encontrar o caminho aumentante mais curto, atualizando os potenciais duais simultaneamente durante a busca. Isso garante que, a cada iteração, o emparelhamento seja aumentado pelo menor custo possível até que a solução ótima completa seja atingida.

A implementação deste algoritmo é bastante complexa, e portanto não será detalhada aqui. No entanto, sua eficiência prática o torna uma escolha preferida para muitos problemas de atribuição em aplicações reais, especialmente quando comparado ao método Húngaro tradicional \cite{jungnickel}.

% TODO: adicionar pseudo-código do algoritmo Jonker-Volgenant
% "A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems"

\paragraph{Redução para problema de fluxo de custo mínimo}
\label{p:reduction_to_minimal_flow}

Similarmente ao que foi feito para o problema de emparelhamento de cardinalidade máxima, o problema de atribuição pode ser resolvido através de uma redução ao problema de fluxo de custo mínimo. Assim como para o problema anterior, essa redução é feita criando dois novos vértices: um vértice fonte $s$ e um vértice sorvedouro $t$. Em seguida, são adicionadas arestas do vértice fonte $s$ para cada vértice de um dos conjuntos do grafo bipartido, com capacidade 1 e custo 0. Também são adicionadas arestas de cada vértice do outro conjunto para o vértice sorvedouro $t$, também com capacidade 1 e custo 0. Finalmente, As arestas do grafo bipartido original são adicionadas com capacidade 1 e custo igual ao custo de atribuição correspondente.

Para resolver problemas de fluxo podemos utilizar algoritmos como o de caminhos de custo mínimo sucessivos (Successive Shortest Paths) ou o algoritmo de cancelamento de ciclos (Cycle canceling) \cite{schrijver}.

% TODO: Incluir também Out-of-kilter, Simplex, e cost-scaling

O primeiro algoritmo, o de caminhos de custo mínimo sucessivos, foi inicialmente proposto por Jewell, Busacker e Gowen e é uma adaptação do algoritmo de Ford-Fulkerson para incorporar o custo das arestas. Em poucas palavras, ele encontra o caminho de $s$ para $t$ de custo mínimo, envia o máximo fluxo possível ao longo desse caminho, e repete esse processo até que não seja mais possível aumentar o fluxo sem violar as capacidades das arestas \cite{schrijver}.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{OPTFLOW($G, c, s, t, \gamma, v; f, \text{sol}$)}{
        % Line 1: Single-line for loop
        \lFor{$e \in E$}{ $f(e) \leftarrow 0$ }
        
        % Line 2
        $\text{sol} \leftarrow \text{true}, \text{val} \leftarrow 0$\;

        % Line 3: While loop
        \While{$\text{sol} = \text{true}$ \KwAnd $\text{val} < v$}{
            
            % Line 4: Descriptive text
            construct the auxiliary network $N' = (G', c', s, t)$ with cost function $\gamma'$\;

            % Line 5: If-Else structure
            \eIf{$t$ is not accessible from $s$ in $G'$}{
                % Line 6
                $\text{sol} \leftarrow \text{false}$\;
            }{
                % Line 7: Descriptive text
                determine a shortest path $P$ from $s$ to $t$ in $(G', \gamma')$\;
                
                % Line 8: Multiple assignments
                $\delta \leftarrow \min \{c'(e) : e \in P \}; \delta' \leftarrow \min(\delta, v - \text{val}); \text{val} \leftarrow \text{val} + \delta'$\;
                
                % Line 9
                augment $f$ along $P$ by $\delta'$\;
            }
        }
    }
    \caption{Algoritmo de caminhos de custo mínimo sucessivos \cite{jungnickel}}
    \label{alg:optflow}
\end{algorithm}

 A complexidade do algoritmo é dependente do método utilizado para encontrar o caminho $P$. A implementação padrão utilizaria o algoritmo de Dijkstra, que tem uma complexidade de $O(E + V \log V)$ em uma implementação com filas de prioridade, onde $V$ é o número de vértices e $E$ o número de arestas. Porém, como o grafo residual pode conter arestas com custos negativos, essa implementação não funcionaria corretamente. Para contornar esse problema, temos duas opções principais:

 \begin{itemize}
    \item \textbf{Utilizar Bellman-Ford:} A solução mais simples e direta é utilizar, ao invés do algoritmo de Dijkstra, o algoritmo de Bellman-Ford para encontrar o caminho de custo mínimo $P$. O Bellman-Ford é mais lento, com uma complexidade de $O(VE)$, mas lida corretamente com arestas de custo negativo.
    \item \textbf{Utilizar a técnica de Potenciais:} Permite que utilizemos o algoritmo de Dijkstra mesmo na presença de arestas de custo negativo.
    
    A cada iteração do loop, encontra-se o caminho de custo mínimo $P$ utilizando Dijkstra com os custos reduzidos. Após encontrar o caminho, os potenciais são atualizados para todos os vértices $v$ alcançáveis a partir de $s$ no grafo residual, ajustando-os conforme a distância mínima encontrada pelo Dijkstra, de acordo com a fórmula $h(v) \leftarrow h(v) + d(s,v)$, onde $d(s,v)$ é a distância mínima de $s$ até $v$ no grafo residual com custos reduzidos.

    Abaixo uma adaptação do algoritmo \ref{alg:optflow} utilizando a técnica de potenciais:

    \begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{OPTFLOW\_DIJKSTRA($G, c, s, t, \gamma, v; f, \text{sol}$)}{
        % Inicialização do Fluxo
        \lFor{$e \in E$}{ $f(e) \leftarrow 0$ }
        
        % Inicialização dos Potenciais (assumindo custos iniciais não negativos)
        \lFor{$x \in V$}{ $\pi(x) \leftarrow 0$ }

        $\text{sol} \leftarrow \text{true}, \text{val} \leftarrow 0$\;

        \While{$\text{sol} = \text{true}$ \KwAnd $\text{val} < v$}{
            
            construct the auxiliary network $N' = (G', c', s, t)$\;
            
            % Definição do Custo Reduzido para o Dijkstra
            \For{$e=(u, v) \in E(G')$}{
                define reduced cost: $w(e) \leftarrow \gamma(e) + \pi(u) - \pi(v)$\;
            }

            % Execução do Dijkstra (Lógica omitida, foco no input/output)
            Run Dijkstra on $N'$ using weights $w$ to find shortest path distances $d(\cdot)$ from $s$\;

            \eIf{$t$ is not accessible from $s$ (i.e., $d(t) = \infty$)}{
                $\text{sol} \leftarrow \text{false}$\;
            }{
                % Atualização dos Potenciais (Passo Crucial)
                \lFor{$x \in V$ such that $d(x) < \infty$}{ $\pi(x) \leftarrow \pi(x) + d(x)$ }
                
                Identify shortest path $P$ from $s$ to $t$ based on $d(\cdot)$\;
                
                % O resto segue o algoritmo original, usando as capacidades residuais c'
                $\delta \leftarrow \min \{c'(e) : e \in P \}; \delta' \leftarrow \min(\delta, v - \text{val}); \text{val} \leftarrow \text{val} + \delta'$\;
                
                augment $f$ along $P$ by $\delta'$\;
            }
        }
    }
    \caption{Adaptação do algoritmo \ref{alg:optflow} utilizando Dijkstra com técnica de potenciais}
    \label{alg:optflow_dijkstra}
\end{algorithm}

A complexidade do algoritmo utilizando Dijkstra com a técnica de potenciais é $O(V (E + V \log V))$, onde $V$ é o número de vértices e $E$ o número de arestas do grafo. Isso ocorre porque, em cada iteração do loop principal, executamos o algoritmo de Dijkstra, que tem complexidade $O(E + V \log V)$, e o número máximo de iterações é limitado por $V$, o número de vértices no grafo bipartido.

\end{itemize}

\subsubsection{Heurísticas}

Assim como no problema de emparelhamento de cardinalidade máxima, as soluções exatas, apesar de apresentarem tempo polinomial, são inviáveis para instâncias muito grandes. A seguir algumas heurísticas que objetivam resolver o problema de atribuição em tempo até mesmo linear ($O(E)$).

\paragraph{Heurística gulosa ordenada}
\label{p:gulosa_ordenada}

Similar à heurística gulosa simples descrita na seção \ref{p:h_gulosa_simples}, com a diferença de que a ordem das arestas não é mais arbitrária, e sim decrescente por peso. Tem a mesma garantia de metade do peso ótimo, mas tem complexidade $O(E \log E)$ por conta da ordenação.

% É EXATO
% \paragraph{Algoritmo de leilão com $\epsilon$-scaling}

% O Algoritmo de Leilão (\textbf{Auction Algorithm}), descrito em \citeonline{berstekas} e \citeonline{berstekas1988}, resolve o problema da atribuição maximizando o benefício total através de um processo iterativo de lances e aumentos de preços, análogo a um leilão do mundo real.

% Considere $N$ pessoas e $N$ objetos.
% \begin{itemize}
%     \item $a_{ij}$: O valor (benefício) que a pessoa $i$ atribui ao objeto $j$.
%     \item $p_j$: O preço atual do objeto $j$.
% \end{itemize}

% O objetivo de cada pessoa $i$ é maximizar seu próprio \textbf{lucro líquido}:
% \begin{equation}
%     \text{Lucro}_{ij} = a_{ij} - p_j
% \end{equation}

% Em um equilíbrio de mercado (solução ótima), cada pessoa deve estar designada a um objeto que maximize seu lucro pessoal, e os preços devem ser tais que todos estejam satisfeitos. Isso corresponde, na teoria de dualidade, à condição de \textbf{Folga Complementar}.

% Se exigirmos que cada pessoa pegue *estritamente* o melhor objeto, o algoritmo pode entrar em um loop infinito de "guerra de preços" com incrementos nulos ou infinitesimais. Para garantir a convergência, Bertsekas introduziu o conceito de $\epsilon$-CS (Folga Complementar Epsilon).

% Uma atribuição é $\epsilon$-ótima se cada pessoa $i$ designada ao objeto $j$ estiver a uma distância $\epsilon$ de seu lucro máximo:

% \begin{equation}
%     (a_{ij} - p_j) \ge \max_{k} (a_{ik} - p_k) - \epsilon
% \end{equation}

% O Passo do Leilão:
% \begin{enumerate}
%     \item Uma pessoa não designada $i$ escolhe o objeto $j^*$ que oferece o maior lucro.
%     \item Ela calcula a diferença entre o lucro do melhor objeto e o lucro do segundo melhor objeto ($\gamma$).
%     \item Ela faz um lance para o objeto $j^*$, aumentando seu preço $p_{j^*}$ em:
%         $$\Delta p = \gamma + \epsilon$$
%     \item A pessoa $i$ ganha o objeto, e quem estava com ele (se houvesse alguém) torna-se não designado e volta à fila para dar lances.
% \end{enumerate}

% O termo $\epsilon$ é crucial: ele garante que o preço suba pelo menos um valor fixo a cada lance, impedindo loops infinitos e forçando o algoritmo a terminar. A escolha do valor de $\epsilon$ é muito importante pois define a eficiência do algoritmo:

% \begin{itemize}
%     \item Se $\epsilon$ for \textbf{grande}: O algoritmo termina muito rápido (poucos lances para resolver conflitos), mas a solução é de baixa qualidade (distante do ótimo).
%     \item Se $\epsilon$ for \textbf{pequeno}: A solução é muito próxima ou igual à ótima, mas o algoritmo é lento (muitos incrementos pequenos de preço necessários).
% \end{itemize}

% O conceito de $\epsilon$-scaling consiste em um refinamento sucessivo do valor de $\epsilon$:

% \begin{enumerate}
%     \item Comece com um $\epsilon$ grande (ex: metade do maior peso da aresta).
%     \item Rode o leilão até convergir (todos emparelhados).
%     \item Reduza o valor de $\epsilon$ (ex: $\epsilon \leftarrow \epsilon / 4$).
%     \item Mantenha os preços ($p_j$) e a atribuição da fase anterior. Reinicie o leilão com o novo $\epsilon$.
% \end{enumerate}

% Ao reutilizar os preços, as fases subsequentes convergem muito mais rápido do que se começassem do zero, pois os preços já estão "quase" certos. O processo repete-se até que $\epsilon < 1/N$, momento em que a solução obtida é comprovadamente a ótima inteira (para pesos inteiros).

% A complexidade do algoritmo (usando $\epsilon$-scaling) é de $O(N \cdot E \log(C))$, onde $C$ é o maior custo da aresta. Uma melhoria significativa dos algoritmos $O(N^3)$, como o Método Húngaro. Além disso, o algoritmo é paralelizável, pois permite que as pessoas façam lances simultaneamente, sendo ideal para aplicações onde é possível utilizar GPUs ou clusters distribuídos para o processamento.

% TODO: (pós TCC I): aproximação via Sinkhorn
% #### F. Aproximação via Sinkhorn (Soft Assignment)
% Muito popular atualmente em *Deep Learning* e Visão Computacional.
% * **Funcionamento:** Relaxa a restrição de "inteiro" (0 ou 1) para contínuo (probabilidade). Aplica normalização iterativa de linhas e colunas na matriz de custos (Algoritmo de Sinkhorn-Knopp).
% * **Resultado:** Gera uma matriz duplamente estocástica que aproxima a permutação ótima. Uma passagem final gulosa converte isso em uma atribuição discreta.
% * **Complexidade:** $O(k \cdot N^2)$ onde $k$ é pequeno. Muito rápido em hardware paralelo.

\newpage
\begin{table}[ht]
    \centering
    \caption{Algoritmos para problema de atribuição}
    \label{tab:atribuicao_algos}
    \renewcommand{\arraystretch}{1.2} % Adds a little vertical padding
    
    % Structure: l = left align, c = center, X = auto-wrap paragraph
    \begin{tabularx}{\textwidth}{@{} l l l X @{}}
        \toprule
        \textbf{Algoritmo} & \textbf{Complexidade de tempo} & \textbf{Tipo} & \textbf{Descrição} \\
        \midrule
        
        Método Húngaro & $O(VE)$ & Exato & 
        Método primal-dual que mantém folga complementar para custo mínimo em bipartidos. \\
        \addlinespace 
        
        Jonker-Volgenant & $O(VE^2)$ & Exato & 
        Algoritmo primal-dual eficiente que combina redução de custos inicial e busca de caminhos aumentantes com atualização otimizada de duais. \\
        \addlinespace
        
        Custo mínimo (Bellman-Ford) & $O(EV)$ & Exato & 
        Método de caminhos sucessivos que usa Bellman-Ford para encontrar caminhos na rede residual, suportando custos negativos iniciais. \\
        \addlinespace
        
        Custo mínimo (Dijkstra) & $O(V(E+V \log V))$ & Exato & 
        Utiliza potenciais de vértices para manter custos reduzidos não-negativos, permitindo o uso do eficiente Dijkstra para aumentos sucessivos. \\
        \addlinespace
        
        Gulosa ordenada & $O(E \log E)$ & Heurística & 
        Ordena as arestas por peso decrescente e seleciona iterativamente as disponíveis. \\

        \bottomrule
    \end{tabularx}
\end{table}

