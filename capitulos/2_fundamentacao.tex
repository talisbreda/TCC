%!TeX root = ../main.tex
\section{Fundamentação teórica}

% ==================================================================================================================================
% 2.1. Definições sobre grafos
% ==================================================================================================================================
\subsection{Definições sobre grafos}


Um \textbf{grafo} $G$ é uma uma estrutura definida por um par $G=(V,E)$, consistindo de um conjunto finito $V$ de elementos 
chamados \textbf{vértices} (ou \textbf{nós} ou \textbf{pontos}) e um conjunto (ou família) $E$ de pares não ordenados de vértices, 
chamados de \textbf{arestas} \cite{jungnickel}. O conjunto V é o conjunto de vértices de $G (VG)$ e $E$ é a família de arestas de 
$G (EG)$.

No contexto deste projeto, assumimos que as arestas $e={u,v}$ são pares não ordenados de vértices distintos. Se uma aresta $e$ 
conecta os vértices $a$ e $b$, diz-se que $a$ e $b$ são \textbf{adjacentes} ou \textbf{vizinhos}, e que a aresta $e$ é 
\textbf{incidente} a $a$ e $b$ \cite{schrijver}.

O conceito de grafo é amplamente utilizado como uma representação abstrata concisa para estruturas complexas e para 
codificar relações binárias entre um conjunto de objetos.

% ---------------------------------------------------------------------------------------------------------------------------------
% 2.1.1. Grafo direcionado
% ---------------------------------------------------------------------------------------------------------------------------------
\subsubsection{Grafo direcionado}

Se as relações entre os vértices forem assimétricas, utilizamos um \textbf{grafo direcionado} ou \textbf{dígrafo}, $D=(V,A)$. 
Neste caso, $A$ é uma família de pares ordenados de vértices, chamados \textbf{arcos} (ou arestas direcionadas). 
Para um arco $e=(u,v)$, $u$ é chamado o vértice inicial ou \textbf{cauda} (tail), e $v$ é o vértice final ou \textbf{cabeça} (head)
\cite{manber}

% ---------------------------------------------------------------------------------------------------------------------------------
% 2.1.2. Grafo ponderado
% ---------------------------------------------------------------------------------------------------------------------------------
\subsubsection{Grafo ponderado}

Um grafo $G=(V,E)$ é chamado \textbf{grafo ponderado} (ou com pesos) se uma \textbf{função de peso} (ou função de custo, 
ou função de comprimento) $w:E\rightarrow R$ está associada às arestas. Formalmente: $G=(V,E,w)$, onde $w:E\rightarrow R$. 
Geralmente, o peso $w(e)$ de uma aresta $e$ é um valor real não negativo que representa o custo, comprimento ou capacidade 
associada àquela aresta \cite{rosen}.

Grafos ponderados podem ser representados por matrizes de adjacência de valor real $A$, onde a entrada $A_{ij}$ 
é o peso $w_{ij}$ da aresta \cite{path_following_algo}

% ---------------------------------------------------------------------------------------------------------------------------------
% 2.1.3. Grafo bipartido
% ---------------------------------------------------------------------------------------------------------------------------------
\subsubsection{Grafo bipartido}

Um grafo bipartido é um grafo não direcionado que pode ser facilmente colorido com apenas duas cores \cite{manber}

Formalmente, um grafo $G=(V,E)$ é chamado \textbf{grafo bipartido} se o conjunto de vértices $V$ puder ser
particionado em dois subconjuntos disjuntos $V_1$ e $V_2$, chamados calsses de cor, tais que:

\begin{equation}
    V = V_1 \cup V_2 \quad {e} \quad V_1 \cap V_2 = \emptyset
\end{equation}

e todas as arestas $e \in E$ conectam um vértice em $V_1$ a um vértice em $V_2$. Ou seja, não existem arestas que conectem
vértices dentro do mesmo subconjunto \cite{dasgupta}.

Observações:
\begin{itemize}
    \item Um grafo é bipartido se e somente se não contém ciclos de comprimento ímpar \cite{schrijver}
    \item O grafo bipartido completo $K_{m,n}$ possui $m$ vértices em $V_1$ e $n$ vértices em $V_2$, 
    e contém todas as arestas possíveis entre $V_1$ e $V_2$ \cite{jungnickel}
\end{itemize}


% TODO: teorema da integralidade
% TODO: Mendelsohn-Dulmage

\subsection{Busca em grafos}

A exploração sistemática dos vértices e arestas de um grafo é uma sub-rotina fundamental para a maioria dos algoritmos em redes, incluindo aqueles utilizados para encontrar emparelhamentos, fluxo máximo e componentes conexos. A busca em grafos consiste em seguir as arestas do grafo para visitar os vértices, permitindo descobrir a estrutura da rede e propriedades de conectividade \cite{cormen}.

\subsubsection{Representação computacional}

Antes de discutir os algoritmos de busca, é essencial definir como o grafo $G=(V,E)$ é representado computacionalmente, pois isso impacta diretamente a complexidade temporal das operações. Destacam-se duas representações primárias \cite{aho}:

\begin{itemize}
    \item \textbf{Matriz de adjacência:} Uma matriz $A$ de dimensão $|V| \times |V|$, onde $A_{ij} = 1$ se existe uma aresta $(i,j) \in E$, e $0$ caso contrário. Embora permita verificação de existência de arestas em tempo constante $O(1)$, ela consome espaço $\theta(V^2)$ ,sendo ineficiente para grafos esparsos.
    \item \textbf{Matriz de adjacência:} Consiste em um array de $|V|$ e listas, onde caad lista $Adj[u]$ contém todos os vértices $v$ tal que $(u,v) \in E$. Esta representação é preferível para grafos esparsos, pois consome espaço $\theta(V+E)$ \cite{cormen}.
\end{itemize}

Para os algoritmos de busca descritos a seguir, assume-se geralmente o uso de listas de adjacência, resultando em complexidades lineares em relação ao tamanho do grafo.

\subsubsection{Busca em largura}

A \textbf{busca em largura}, ou Breadth-First Search (BFS) é um dos algoritmos mais simples e fundamentais para a exploração de grafos. A BFS explora o grafo em "camadas" ou níveis. Dado um vértice fonte $s$, o algoritmo visita primeiro todos os vizinhos de $s$ (camada $L_1$), depois os vizinhos desses vizinhos (camada $L_2$), e assim sucessivamente \cite{kleinberg}.

O procedimento utiliza uma estrutura de dados do tipo Fila (FIFO) para gerenciar a fronteira de exploração. \citeonline{cormen} descrevem o uso de um sistema de "cores" para monitorar o estado dos vértices: brancos (não descobertos), cinzas (descobertos, mas com vizinhos ainda não explorados) e pretos (totalmente explorados).

\textbf{Propriedades e Complexidade:} A propriedade mais importante da BFS, destacada por \citeonline{dasgupta}, é que ela calcula o caminho mais curto (em número de arestas) de $s$ a todos os outros vértices alcançáveis em grafos não ponderados. A complexidade de tempo da BFS é $O(V+E)$, pois cada vértice é enfileirado no máximo uma vez e cada lista de adjacência é varrida uma única vez.

\subsubsection{Busca em profundidade}

A \textbf{busca em profundidade} ou Depth-First Search (DFS), ao contrário da estratégia por níveis da BFS, a busca em profundidade explora as arestas a partir do vértice mais recentemente descoberto que ainda possui arestas inexploradas. Conforme \citeonline{manber}, a DFS "aprofunda-se" no grafo tanto quanto possível e, quando não há mais para onde ir, realiza o backtracking (retrocesso) para explorar outros caminhos.

Computacionalmente, a DFS pode ser implementada de forma recursiva ou utilizando uma Pilha (LIFO). Uma característica crucial da DFS é a classificação temporal dos eventos. \citeonline{cormen} sugerem registrar dois carimbos de tempo para cada vértice $u$:

\begin{itemize}
    \item $d[u]$: Momento de descoberta (quando o vértice passa de branco para cinza).
    \item $f[u]$: Momento de finalização (quando o vértice passa de cinza para preto, após toda sua lista de adjacência ser explorada).
\end{itemize}

\textbf{Classificação de arestas}: a execução da DFS induz uma estrutura de floresta (Floresta DFS) e permite classificar as arestas do grafo original em quatro tipos, fundamentais para entender ciclos e estrutura \cite{cormen}
\begin{itemize}
    \item \textbf{Arestas de Árvore:} Arestas $(u,v)$ percorridas pela busca quando $v$ é descoberto.
    \item \textbf{Arestas de Retorno (Back edges):} Conectam um vértice $u$ a um ancestral $v$ na árvore DFS. A existência destas arestas indica a presença de ciclos.
    \item \textbf{Arestas de Avanço (Forward edges):} Conectam $u$ a um descendente $v$ que não é seu filho direto.
    \item \textbf{Arestas de Cruzamento (Cross edges):} Conectam vértices sem relação de ancestralidade.
\end{itemize}

A complexidade da DFS, assim como a BFS, é $\theta(V+E)$ para grafos representados por listas de adjacência.


\subsection{Caminhos mais curtos}

O problema de encontrar o caminho mais curto entre dois vértices em um grafo é um dos problemas de otimização combinatória mais estudados, servindo como sub-rotina para diversas aplicações, incluindo roteamento de redes e algoritmos de fluxo.

Seja $G=(V,E)$ um grafo ponderado com uma função de peso $w : E \rightarrow \mathbb{R}$. O peso de um caminho $p = \langle v_0, v_1 \dots, v_k \rangle$ é a soma dos pesos de suas arestas constituintes: $w(p) = \sum_{i=1}^{k}w(v_{i-1},v_i)$. O \textbf{caminho mais curto} de um vértice $u$ a um vértice $v$ é definido como qualquer camino $p$ com peso mínimo $\delta(u,v)$ \cite{cormen}.

\subsubsection{Princípio do relaxamento e subestrutura ótima}

Os algoritmos de caminho mínimo baseiam-se na propriedade de \textbf{subestrutura ótima}: subcaminhos de um caminho mais curto são, por si mesmos, caminhos mais curtos. Além disso, utilizam a técnica de \textbf{relaxamento} \cite{kleinberg}.

Para cada vértice $v$, o algoritmo mantém um atributo $d[v]$, que é um limite superior para o peso do caminho mais curto da fonte $s$ até $v$. O processo de relaxar uma aresta $(u,v)$ consiste em testar se é possível melhorar o caminho para $v$ passando por $u$:

\begin{equation}
    \text{Se } d[v] > d[u] + w(u,v)\text{, então } d[v] \leftarrow d[u] + w(u,v)
\end{equation}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined
        \Fn{Relax($u, v, w$)}{
        \If{$v.d > u.d + w(u, v)$}{
            $v.d \leftarrow u.d + w(u, v)$\;
            $v.\pi \leftarrow u$\;
        }
    }
    \caption{Método de relaxamento \cite{cormen}}
\end{algorithm}

A diferença entre os algoritmos reside na ordem e na frequência com que as arestas são relaxadas.

\subsubsection{Algoritmo de Dijkstra}

Para grafos onde os pesos das arestas são não-negativos ($w(u,v)\geq 0$), o Algoritmo de Dijkstra é a abordagem mais eficiente. Ele utiliza uma estratégia gulosa, mantendo um conjunto de vértices cujos pesos finais dos caminhos mais curtos já foram determinados \cite{aho}.

O algoritmo seleciona repetidamente o vértice $u$ com a menor estimativa de caminho mais curto $d[u]$ de uma fila de prioridade, adiciona-o ao conjunto de visitados e relaxa todas as arestas que saem de $u$. \citeonline{dasgupta} destacam que a eficiência do Dijkstra depende da estrutura de dados utilizada. Com um Heap Binário, a complexidade é $O((V+E)\log V)$. \citeonline{cormen} apontam que, ao utilizar um Heap de Fibonacci, a complexidade amortizada pode ser reduzida para $O(E+VlogV)$, o que é crucial para grafos densos.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{Dijkstra($G, w, s$)}{
        Initialize-Single-Source($G, s$)\;
        $S \leftarrow \emptyset$\;
        $Q \leftarrow G.V$\;
        \While{$Q \neq \emptyset$}{
            $u \leftarrow \text{Extract-Min}(Q)$\;
            $S \leftarrow S \cup \{u\}$\;
            \ForEach{vertex $v \in G.Adj[u]$}{
                Relax($u, v, w$)\;
            }
        }
    }
    \caption{Algoritmo de Dijkstra \cite{cormen}}
\end{algorithm}

\subsubsection{Algoritmo de Bellman-Ford}

Quando o grafo contém arestas com pesos negativos, o algoritmo de Dijkstra não garante a corretude. Nesses casos, utiliza-se o Algoritmo de Bellman-Ford. Segundo \citeonline{manber}, este algoritmo baseia-se em programação dinâmica, relaxando todas as arestas do grafo $|V|-1$ vezes.

A propriedade fundamental do Bellman-Ford é sua capacidade de detectar ciclos negativos. Se, após $|V|-1$ iterações, ainda for possível relaxar alguma aresta, o grafo contém um ciclo com peso total negativo acessível a partir da fonte, o que implica que $\delta(s,v)=-\infty$ para alguns vértices \cite{kleinberg}. Sua complexidade é $O(VE)$.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{Bellman-Ford($G, w, s$)}{
        Initialize-Single-Source($G, s$)\;
        \For{$i = 1$ \KwTo $|G.V| - 1$}{
            \ForEach{edge $(u, v) \in G.E$}{
                Relax($u, v, w$)\;
            }
        }
        \ForEach{edge $(u, v) \in G.E$}{
            \If{$v.d > u.d + w(u, v)$}{
                \KwRet \KwFalse\;
            }
        }
        \KwRet \KwTrue\;
    }
    \caption{Algoritmo de Bellman-Ford \cite{cormen}}
\end{algorithm}

\subsubsection{Algoritmo de Floyd-Warshall}

Enquanto Dijkstra e Bellman-Ford resolvem o problema de fonte única (Single-Source), o algoritmo de Floyd-Warshall resolve o problema de caminhos mais curtos entre todos os pares de vértices (All-Pairs).

\citeonline{aho} explicam que o algoritmo utiliza programação dinâmica baseada na numeração dos vértices. Seja $d_{ij}^{(k)}$ o peso do caminho mais curto de $i$ a $j$ utilizando apenas vértices do conjunto ${1,2,\dots,k}$ como intermediários. A recorrência é dada por:

\begin{equation}
    d_{ij}^{(k)} = \min(d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)})
\end{equation}

A complexidade temporal é $\theta(V^3)$. \citeonline{jungnickel} observa que, para grafos densos, este método é geralmente mais eficiente do que executar o algoritmo de Bellman-Ford a partir de cada vértice.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{Floyd-Warshall($W$)}{
        $n \leftarrow W.rows$\;
        $D^{(0)} \leftarrow W$\;
        \For{$k = 1$ \KwTo $n$}{
            \KwLet $D^{(k)} = (d_{ij}^{(k)})$ be a new $n \times n$ matrix\;
            \For{$i = 1$ \KwTo $n$}{
                \For{$j = 1$ \KwTo $n$}{
                    $d_{ij}^{(k)} \leftarrow \min \left( d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)} \right)$\;
                }
            }
        }
        \KwRet $D^{(n)}$\;
    }
    \caption{Algoritmo de Floyd-Warshall \cite{cormen}}
\end{algorithm}

% 2.7.5. Reponderação e Algoritmo de Johnson

% Uma técnica avançada, relevante para algoritmos de fluxo de custo mínimo, é a reponderação de arestas para eliminar pesos negativos sem alterar os caminhos mais curtos. O Algoritmo de Johnson combina Bellman-Ford e Dijkstra.

% Conforme descrito por Cormen et al. (2009) e Ahuja et al. (1993), utiliza-se uma função de potencial h:V→R tal que o novo peso da aresta seja w^(u,v)=w(u,v)+h(u)−h(v)≥0. Se o grafo não contiver ciclos negativos, é possível calcular tais potenciais (usando Bellman-Ford uma vez) e subsequentemente rodar Dijkstra para cada vértice, obtendo uma complexidade assintótica melhor que Floyd-Warshall para grafos esparsos: O(V2logV+VE).

\subsection{Redes de fluxo em grafos}

A teoria dos fluxos em redes é um ramo fundamental da otimização combinatória que modela problemas de transporte de recursos através de um sistema conectado. Esta seção define os conceitos preliminares e apresenta os teoremas centrais que sustentam os algoritmos utilizados neste trabalho.

\subsubsection{Definições básicas}

Uma rede de fluxo é definida por um grafo direcionado $G = (V, E)$, onde $V$ é o conjunto de vértices e $E$ é o conjunto de arestas. Distinguem-se dois vértices especiais: a \textbf{fonte} $s\in V$. que produz o fluxo, e o \textbf{sorvedouro} $t\in V$, que o consome. Para cada aresta $(u, v) \in E$, associa-se uma capacidade não-negativa $c(u,v) \geq o$, que limita a quantidade de fluxo que pode atravessar aquela aresta. Um \textbf{fluxo} em $G$ é uma função $f \space : \space E \rightarrow \mathbb{R}^+$ que satisfaz as seguintes propriedades \cite{cormen}:

\begin{itemize}
    \item \textbf{Restrição de capacidade:} O fluxo em uma aresta não pode exceder a sua capacidade.
    \begin{equation}
        \label{eq:capacity_restraint}
        0 \leq f(u,v) \leq c(u,v), \qquad \forall(u,v) \in E
    \end{equation}
    \item \textbf{Conservação de fluxo:} para todo vértice $v \in V - \{s,t\}$, a quantidade total de fluxo que entra deve ser igual à que sai
    \begin{equation}
        \sum_{v \in V}f(v,u) = \sum_{v \in V}f(u,v)
    \end{equation}
\end{itemize}

\subsubsection{O problema do fluxo máximo}

O \textbf{problema do fluxo máximo} consiste em encontrar um fluxo $f$ tal que $|f|$ seja o maior possível. Para entender a limitação desse fluxo, precisamos entender os conceitos de corte, redes residuais e caminhos aumentantes.

\paragraph{Corte}

Um \textbf{corte} $(S,T)$ é uma partição do conjunto de vértices $V$ em dois subconjuntos disjuntos $S$ e $T$, tal que $s\in S$ e $t\in T$. A \textbf{capacidade do corte}, denotada por $c(S,T)$, é a soma das capacidades das arestas que partem de $S$ para $T$ \cite{cormen}:

\begin{equation}
    c(S,T) = \sum_{u\in S,v\in T}c(u,v)
\end{equation}

O \textbf{corte mínimo} de uma rede $N$ é um corte cuja capacidade é a menor entre todos os cortes possíveis nessa rede \cite{cormen}. Isso nos leva ao \textbf{teorema do fluxo máximo e corte mínimo (Max-flow Min-cut)}

\begin{quotation}
    \textit{O valor máximo do fluxo de uma rede $N$ é igual à capacidade do corte mínimo em $N$ \cite{jungnickel}}
\end{quotation}

Este teorema é fundamental para a compreensão e corretudo dos algoritmos de caminhhos aumentantes.

\paragraph{Redes residuais}

A maioria dos algoritmos de resolução de problemas de fluxo máximo se baseia no conceito de redes residuais. Uma \textbf{rede residual} $G_f$ consiste em arestas com capacidades que representam como podemos alterar o fluxo das arestas em $G$. A capacidade das arestas da rede residual $G_f$ corresponde à diferença entre a capacidade da aresta original de $G$ e o fluxo $f$ que está passando pela aresta \cite{cormen}. Ou seja:

\begin{equation}
    c_f(u,v) = c(u,v) - f(u,v)
\end{equation}

Quando a aresta $(u,v)$ possui fluxo igual à sua capacidade, então $c_f(u,v) = 0$ e a aresta não é incluída no grafo residual $G_f$

\paragraph{Caminhos aumentantes}
\label{p:ford_fulkerson}

Dado um grafo $G=(V,E)$ e um fluxo $f$, um \textbf{caminho aumentante} é um caminho de $s$ para $t$ na rede residual $G_f$. Por definição, podemos aumentar o fluxo em uma aresta $(u,v)$ de um caminho aumentante em até $c_f(u,v)$ sem violar a capacidade da aresta original em $G$ \cite{cormen}.

O método de Ford-Fulkerson, que é base dos principais algoritmos de resolução do problema do fluxo máximo, iterativamente encontra um caminho aumentante, calcula sua capacidade residual e adiciona esse fluxo à solução atual até que não existam mais caminhos aumentantes \cite{ahuja}.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined

    \Fn{FORD-FULKERSON($G, s, t$)}{
        \ForEach{edge $(u, v) \in G.E$}{
            $(u, v).f \leftarrow 0$\;
        }
        
        \While{there exists a path $p$ from $s$ to $t$ in the residual network $G_f$}{
            $c_f(p) \leftarrow \min \{ c_f(u, v) : (u, v) \text{ is in } p \}$\;
            
            \ForEach{edge $(u, v) \in p$}{
                \eIf{$(u, v) \in E$}{
                    $(u, v).f \leftarrow (u, v).f + c_f(p)$\;
                }{
                    $(v, u).f \leftarrow (v, u).f - c_f(p)$\; 
                }
            }
        }
    }
    
    \caption{Ford-Fulkerson Algorithm}
    \label{alg:ford_fulkerson}
\end{algorithm}

\subsubsection{Fluxo de custo mínimo}

Uma outra variação dos problemas em redes de fluxo em grafos é o problema do fluxo de custo mínimo. Essa variação considera, além das capacidades disponíveis, uma dimensão econômica. Seja $G=(V, E)$ uma rede direcionada one cada aresta $(u,v)$ possui uma capacidade $c(u,v)$ e um custo unitário $w(u,v)$. O objetivo é transmitir uma quantidade de fluxo pré-determinada $F$ da fonte $s$ ao sorvedouro $t$ com o menor custo total possível.

A formulação linear do problema é dada por \citeonline{ahuja}. O primeiro objetivo é minimizar o custo total do fluxo, que segue a fórmula:

\begin{equation}
    \text{Minimizar o custo do fluxo:}\quad z(f) = \sum_{(u,v)\in A} w(u,v) \cdot f(u,v)
\end{equation}

A função a seguir assegura que o nó fonte $s$ gere exatamente a demanda $F$, e que o nó sorvedouro $t$ absorva-a integralmente. 

\begin{equation}
    \sum_{i,j\in V}f(i,j) - \sum_{k,i\in V}f(k,i) = 
        \begin{cases}
            F  & \text{se } i = s \\
            -F & \text{se } j = t \\
            0  & \text{caso contrário}
        \end{cases}
\end{equation}

Além desta, é importante lembrar da equação \ref{eq:capacity_restraint}, que define que o fluxo em uma aresta não pode exceder a sua capacidade.

\paragraph{Condições de otimalidade e ciclos negativos}

O critério fundamental para verificar se uma solução é ótima é o \textbf{teorema dos ciclos negativos}:

\begin{quotation}
    Um fluxo $f$ é uma solução viável para o problema do fluxo de custo mínimo se e somente se ele satisfaz a condição de otimalidade de ciclo negativo: a rede resiual $G(f)$ não contém um ciclo e custo negativo \cite{ahuja}
\end{quotation}

Este teorema é a base dos algoritmos de \textbf{cancelamento de ciclos} (Cycle Canceling), que iterativamente identificam ciclos negativos na rede residual e enviam fluxo através deles para reduzir o custo total da função objetivo até que nenhum ciclo negativo reste.

\paragraph{Potenciais de vértices e custos reduzidos}

Embora o cancelamento de ciclos seja teoricamente sólido, a detecção de ciclos negativos (via Bellman-Ford) pode ser computacionalmente custosa. Para permitir o uso de algoritmos mais eficientes como o de Dijkstra, a literatura introduz o conceito de \textbf{potenciais de vértices}, baseando-se na teoria de dualidade da programação linear.

A ideia é manter um \textbf{potencial} para cada vértice $v$ do grafo, chamado de $h(v)$, com valor inicial 0. Definimos o \textbf{custo reduzido} de uma aresta $(u,v)$ como $\gamma'(u,v) = \gamma(u,v) + h(u) - h(v)$. Se os potenciais forem escolhidos de forma adequada, todos os custos reduzidos podem ser garantidos como não-negativos, permitindo o uso do algoritmo de Dijkstra. Além disso, é garantido que os caminhos de custo mínimo no grafo original e no grafo com custos reduzidos são os mesmos. \cite{jungnickel}.

O conceito de potenciais e de custo reduzido será utilizado em algoritmos como o de caminhos sucessivos para resolução do problema de atribuição na seção \ref{p:reduction_to_minimal_flow}.

% ==================================================================================================================================
% 2.2. Problema Geral do Emparelhamento
% ==================================================================================================================================
\subsection{Problema Geral do Emparelhamento}

O problema de \textbf{matching} (emparelhamento) em grafos é um problema fundamental na otimização combinatória

Um \textbf{matching} M em um grafo não-direcionado $G=(V,E)$ é um subconjunto de arestas $M \subseteq E$ tal que
nenhum par de arestas em $M$ compartilha um vértice comum \cite{kleinberg}. Em outras palavras, cada nó aparece em no máximo uma aresta de $M$.

\begin{itemize}
    \item Um vértice é chamado \textbf{coberto} (\textit{matched}) se for incidente a uma aresta em $M$; caso contrário, 
    é \textbf{descoberto} (\textit{unmatched} ou \textit{exposed}) \cite{cormen}
    \item Um \textbf{matching de cardinalidade máxima} (Maximum Matching) é um matching com o maior número possível 
    de arestas \cite{cormen}. A cardinalidade máxima de um matching é denotada por $v(G)$ \cite{schrijver}
    \item Um \textbf{matching perfeito} é um matching que cobre todos os vértices do grafo \cite{kleinberg}
    \item  O \textbf{problema de matching ponderado} (Weighted Matching Problem) envolve encontrar um matching para o qual a 
    soma dos pesos das arestas é máxima. Em um grafo ponderado $G=(V,E,w)$, busca-se um $M\subseteq E$ que maximize $w(M)$ \cite{matching_gpus_sc24}
\end{itemize}

% ---------------------------------------------------------------------------------------------------------------------------------
% 2.2.1. Matching em grafos bipartidos
% ---------------------------------------------------------------------------------------------------------------------------------
\subsubsection{Matching em grafos bipartidos}

O problema de \textbf{Matching Bipartido} é o caso clássico de encontrar um matching de cardinalidade máxima em um grafo 
bipartido $G=(V,E)$, onde $V=X\cup Y$ \cite{kleinberg}

\begin{itemize}
    \item O matching em grafos bipartidos pode modelar situações de atribuição, como associar empregos ($X$) a máquinas ($Y$), 
    ou professores ($X$) a cursos ($Y$), onde uma aresta indica uma capacidade de atribuição \cite{kleinberg}
    \item O problema de matching ponderado em grafos bipartidos é equivalente ao \textbf{problema de atribuição \cite{lawler}}, 
    que historicamente motivou o desenvolvimento do \textbf{método Húngaro} \cite{schrijver}
\end{itemize}

% ---------------------------------------------------------------------------------------------------------------------------------
% 2.2.2. Formulação geral (emparelhamento e otimização)
% ---------------------------------------------------------------------------------------------------------------------------------
\subsubsection{Formulação geral (emparelhamento e otimização)}

Em um contexto mais amplo, o emparelhamento de grafos pode ser formalizado como um problema de otimização que 
busca maximizar a compatibilidade entre dois grafos $G$ e $G'$ \cite{learning_graph_matching}.

\begin{itemize}
    \item  O problema de graph matching é frequentemente abordado como um \textbf{problema de atribuição quadrática (QAP)}. 
    Essa formulação busca maximizar uma função objetivo que combina termos de compatibilidade unária (nó-nó, $c_{ii'}$) 
    e compatibilidade par a par (aresta-aresta, $d_{ii'jj'}$), sujeito a restrições de atribuição binária ($y_{ii'} \in {0,1}$). 
    O termo quadrático codifica a preservação das relações (arestas) entre os nós \cite{learning_graph_matching}
    \item Para grafos bipartidos, a determinação de um matching máximo pode ser resolvida de maneira eficiente e está intimamente 
    ligada a problemas de \textit{network flow} (fluxo em redes) \cite{kleinberg}
\end{itemize}
